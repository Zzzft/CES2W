{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de53995b-32ed-4722-8cac-ba104c8efacb",
   "metadata": {},
   "source": [
    "# 导入环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ccc149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52fac949-4150-4091-b0c3-2968ab5e385c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fz/finetune/lora_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098d9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: 8003条 (80.0%)\n",
      "测试集: 2001条 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_json('./dataset/merged_output.json')\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "# 5. 验证划分比例\n",
    "print(f\"训练集: {len(train_ds)}条 ({len(train_ds)/len(df):.1%})\")\n",
    "print(f\"测试集: {len(test_ds)}条 ({len(test_ds)/len(df):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d05e5d-d14e-4f03-92be-9a9677d41918",
   "metadata": {},
   "source": [
    "# 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee5a67-2e55-4974-b90e-cbf492de500a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./model/AI-ModelScope/Mistral-7B-Instruct-v0___2', use_fast=False, trust_remote_code=True)\n",
    "tokenizer.padding_side = \"left\"  # Flash Attention 必须左对齐\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60590653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('</s>', 2, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token, tokenizer.pad_token_id, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503a5fa-9621-4495-9035-8e7ef6525691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 1024    \n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(f\"\"\"<s>[INST]\n",
    "                            你是一位老年服务机构的文书编辑，擅长将老人的口头叙述准确、清晰地转化为日常书面风格的中文文本，并判断语句中存在的错误类型。\n",
    "                            句子中可能存在的错误类型：1. 句子成分缺失。2. 句子结构混乱。3. 句子成分错误。4. 句子成分冗余。\n",
    "                            原文：{example['spoken_text']}\n",
    "                            上下文(仅协助理解，不翻译): {example['context']}\n",
    "                            仅输出原文那一句话的中文转换结果和错误类型序号，不要输出思考过程，不要输出解释。输出格式：\n",
    "                            翻译结果：\n",
    "                            错误类型：\n",
    "                            [/INST]</s>\\n\"\"\", add_special_tokens=False)  # add_special_tokens 不在开头加 special_tokens\n",
    "    # 构建response\n",
    "    response = tokenizer(\n",
    "        f\"翻译结果：{example['written_text']}\\n错误类型：{','.join(map(str, example['error_type']))}\",\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]  # 因为eos token咱们也是要关注的所以 补充为1\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]  \n",
    "    if len(input_ids) > MAX_LENGTH: \n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f870d6-73a9-4b0f-8abf-687b32224ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8003/8003 [00:11<00:00, 707.15 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 8003\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train = train_ds.map(process_func, remove_columns=train_ds.column_names)\n",
    "tokenized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7e15a0-4d9a-4935-9861-00cc472654b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST]\n",
      "                            你是一位老年服务机构的文书编辑，擅长将老人的口头叙述准确、清晰地转化为日常书面风格的中文文本，并判断语句中存在的错误类型。\n",
      "                            句子中可能存在的错误类型：1. 句子成分缺失。2. 句子结构混乱。3. 句子成分错误。4. 句子成分冗余。\n",
      "                            原文：去一回也算，守上几天也算，任家庄街西社区也算抗美援朝老兵。\n",
      "                            上下文(仅协助理解，不翻译): 王家庄街西社区的士兵没有去朝鲜。庄街西社区的部分居民并未参战，即便参战也未曾经历实战。主街西社区的居民承担了守备任务，但街西社区在五六年前已经停战了。任家庄街西社区已经停战，守备部队也已撤回。去一回也算，守上几天也算，任家庄街西社区也算抗美援朝老兵。任家庄街西社区那也算了啊，任家庄街西社你去了吗？任家庄街西社对对对大叔，任家庄街西那您四年以后当兵。4年以后就集体转业吗？就集体转业，送这的，就直接转到大西北来了啊。直接送到这里，哦送了多少人啊？你们一起送了。\n",
      "                            仅输出原文那一句话的中文转换结果和错误类型序号，不要输出思考过程，不要输出解释。输出格式：\n",
      "                            翻译结果：\n",
      "                            错误类型：\n",
      "                            [/INST]</s> \n",
      " 翻译结果：无论是曾赴朝鲜参战，还是仅参与过短期守备任务，任家庄街西社区的居民都可被视为抗美援朝老兵。\n",
      "错误类型：1,2,3</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_train[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f16f66-324a-454f-8cc3-ef23b100ecff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 翻译结果：您坚持包粽子50年，真是不容易啊。\\n错误类型：4</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(filter(lambda x: x != -100, tokenized_train[1][\"labels\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424823a8-ed0d-4309-83c8-3f6b1cdf274c",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170764e5-d899-4ef4-8c53-36f6dec0d198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('./model/AI-ModelScope/Mistral-7B-Instruct-v0___2', \n",
    "                                             device_map=\"auto\",\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                             #attn_implementation=\"flash_attention_2\",\n",
    "                                             use_cache=False,\n",
    "                                             trust_remote_code=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2323eac7-37d5-4288-8bc5-79fac7113402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.enable_input_require_grads() # 开启梯度检查点时，要执行该方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f808b05c-f2cb-48cf-a80d-0c42be6051c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8bb0126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdpa'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config._attn_implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d71257-3c1c-4303-8ff8-af161ebc2cf1",
   "metadata": {},
   "source": [
    "# lora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d304ae2-ab60-4080-a80d-19cac2e3ade3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=8, target_modules={'q_proj', 'down_proj', 'gate_proj', 'o_proj', 'k_proj', 'up_proj', 'v_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    inference_mode=False, # 训练模式\n",
    "    r=8, # Lora 秩\n",
    "    lora_alpha=32, # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1# Dropout 比例\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c2489c5-eaab-4e1f-b06a-c3f914b4bf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fz/finetune/lora_env/lib/python3.10/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/home/fz/finetune/lora_env/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=8, target_modules={'q_proj', 'down_proj', 'gate_proj', 'o_proj', 'k_proj', 'up_proj', 'v_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(model, config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf5482b-fab9-4eb3-ad88-c116def4be12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 20,971,520 || all params: 7,262,703,616 || trainable%: 0.2888\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca055683-837f-4865-9c57-9164ba60c00f",
   "metadata": {},
   "source": [
    "# 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76bbff-15fd-4995-a61d-8364dc5e9ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/mistral\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    save_on_each_node=True,\n",
    "    save_strategy = \"steps\",\n",
    "    gradient_checkpointing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142cb9c-ad99-48e6-ba86-6df198f9ed96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=\"longest\",\n",
    "    pad_to_multiple_of=8,  \n",
    "    return_tensors=\"pt\"     \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    #eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a472a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)  # 将模型移动到 GPU 上\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aec9bc36-b297-45af-99e1-d4c4d82be081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   6/3000 00:11 < 2:29:07, 0.33 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finetune/lora_env/lib/python3.10/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finetune/lora_env/lib/python3.10/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/finetune/lora_env/lib/python3.10/site-packages/transformers/trainer.py:3782\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3780\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/finetune/lora_env/lib/python3.10/site-packages/accelerate/accelerator.py:2454\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2454\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finetune/lora_env/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finetune/lora_env/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/finetune/lora_env/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a86ec",
   "metadata": {},
   "source": [
    "# 保存 LoRA 和 tokenizer 结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e376229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mistral_lora/train3/tokenizer_config.json',\n",
       " './mistral_lora/train3/special_tokens_map.json',\n",
       " './mistral_lora/train3/tokenizer.model',\n",
       " './mistral_lora/train3/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_id=\"./mistral_lora/train3\"\n",
    "trainer.model.save_pretrained(peft_model_id)\n",
    "tokenizer.save_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad3980af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2001/2001 [00:03<00:00, 665.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2001' max='2001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2001/2001 03:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6241292357444763,\n",
       " 'eval_runtime': 215.9996,\n",
       " 'eval_samples_per_second': 9.264,\n",
       " 'eval_steps_per_second': 9.264,\n",
       " 'epoch': 2.995502248875562}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test = test_ds.map(process_func, remove_columns=test_ds.column_names)\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.args.per_device_eval_batch_size = 1\n",
    "#trainer.evaluate(tokenized_test.select(range(5)))  # 先试 5 条\n",
    "\n",
    "trainer.evaluate(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823e3c7",
   "metadata": {},
   "source": [
    "# 加载 lora 权重推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dad881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fz/finetune/lora_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "mode_path = './model/AI-ModelScope/Mistral-7B-Instruct-v0___2'\n",
    "lora_path = './mistral_lora/train3'\n",
    "\n",
    "# 加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_path, trust_remote_code=True)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(lora_path, trust_remote_code=True)\n",
    "tokenizer.padding_side = \"left\"\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained(mode_path, device_map=\"auto\",torch_dtype=torch.bfloat16, trust_remote_code=True).eval()\n",
    "\n",
    "# 加载lora权重\n",
    "model = PeftModel.from_pretrained(model, model_id=lora_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ccb63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 假设你已经指定了 device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)  # 将模型移动到 GPU 上\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a38d039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c049e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'file_id', 'spoken_text', 'context', 'written_text', 'error_type', '__index_level_0__'],\n",
       "    num_rows: 2001\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_json('./dataset/test_dataset.json')\n",
    "\n",
    "test_ds = Dataset.from_pandas(df)\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb03834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:   0%|          | 0/251 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/fz/finetune/lora_env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/fz/finetune/lora_env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:   0%|          | 1/251 [00:05<24:35,  5.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   1%|          | 2/251 [00:11<23:56,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   1%|          | 3/251 [00:17<24:03,  5.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   2%|▏         | 4/251 [00:24<25:21,  6.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   2%|▏         | 5/251 [00:29<23:26,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   2%|▏         | 6/251 [00:34<22:41,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   3%|▎         | 7/251 [00:40<22:48,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   3%|▎         | 8/251 [00:44<21:30,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   4%|▎         | 9/251 [00:49<20:26,  5.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   4%|▍         | 10/251 [00:54<20:21,  5.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   4%|▍         | 11/251 [01:00<21:41,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   5%|▍         | 12/251 [01:05<21:22,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   5%|▌         | 13/251 [01:11<22:14,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   6%|▌         | 14/251 [01:17<21:34,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   6%|▌         | 15/251 [01:22<21:42,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   6%|▋         | 16/251 [01:28<22:26,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   7%|▋         | 17/251 [01:33<20:52,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   7%|▋         | 18/251 [01:39<21:10,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   8%|▊         | 19/251 [01:45<21:49,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   8%|▊         | 20/251 [01:50<21:10,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   8%|▊         | 21/251 [01:56<21:26,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   9%|▉         | 22/251 [02:02<21:46,  5.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:   9%|▉         | 23/251 [02:07<21:39,  5.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  10%|▉         | 24/251 [02:12<20:34,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  10%|▉         | 25/251 [02:17<20:23,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  10%|█         | 26/251 [02:23<20:06,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  11%|█         | 27/251 [02:29<21:06,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  11%|█         | 28/251 [02:34<20:10,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  12%|█▏        | 29/251 [02:39<20:06,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  12%|█▏        | 30/251 [02:45<20:12,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  12%|█▏        | 31/251 [02:51<20:21,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  13%|█▎        | 32/251 [02:56<19:43,  5.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  13%|█▎        | 33/251 [03:01<19:27,  5.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  14%|█▎        | 34/251 [03:15<28:24,  7.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  14%|█▍        | 35/251 [03:20<25:47,  7.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  14%|█▍        | 36/251 [03:26<23:56,  6.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  15%|█▍        | 37/251 [03:31<22:42,  6.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  15%|█▌        | 38/251 [03:36<20:50,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  16%|█▌        | 39/251 [03:42<20:23,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  16%|█▌        | 40/251 [03:47<19:41,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  16%|█▋        | 41/251 [03:52<19:15,  5.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  17%|█▋        | 42/251 [03:57<18:40,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  17%|█▋        | 43/251 [04:02<18:29,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  18%|█▊        | 44/251 [04:08<18:36,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  18%|█▊        | 45/251 [04:13<18:01,  5.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  18%|█▊        | 46/251 [04:18<17:54,  5.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  19%|█▊        | 47/251 [04:23<17:21,  5.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  19%|█▉        | 48/251 [04:30<19:00,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  20%|█▉        | 49/251 [04:40<23:28,  6.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  20%|█▉        | 50/251 [04:45<21:46,  6.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  20%|██        | 51/251 [04:51<20:41,  6.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  21%|██        | 52/251 [04:57<20:49,  6.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  21%|██        | 53/251 [05:02<19:30,  5.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  22%|██▏       | 54/251 [05:08<19:14,  5.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  22%|██▏       | 55/251 [05:14<19:11,  5.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  22%|██▏       | 56/251 [05:20<19:04,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  23%|██▎       | 57/251 [05:26<18:53,  5.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  23%|██▎       | 58/251 [05:32<18:59,  5.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  24%|██▎       | 59/251 [05:37<18:18,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  24%|██▍       | 60/251 [05:44<19:26,  6.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  24%|██▍       | 61/251 [05:50<18:53,  5.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  25%|██▍       | 62/251 [05:55<18:13,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  25%|██▌       | 63/251 [05:59<16:50,  5.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  25%|██▌       | 64/251 [06:04<16:17,  5.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  26%|██▌       | 65/251 [06:10<16:57,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  26%|██▋       | 66/251 [06:17<17:40,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  27%|██▋       | 67/251 [06:23<18:26,  6.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  27%|██▋       | 68/251 [06:30<18:49,  6.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  27%|██▋       | 69/251 [06:36<18:22,  6.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  28%|██▊       | 70/251 [06:42<18:15,  6.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  28%|██▊       | 71/251 [06:49<18:52,  6.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  29%|██▊       | 72/251 [06:54<17:50,  5.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  29%|██▉       | 73/251 [06:58<16:36,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  29%|██▉       | 74/251 [07:05<17:01,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  30%|██▉       | 75/251 [07:10<16:56,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  30%|███       | 76/251 [07:16<16:45,  5.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  31%|███       | 77/251 [07:22<16:46,  5.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  31%|███       | 78/251 [07:27<15:50,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  31%|███▏      | 79/251 [07:33<16:23,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  32%|███▏      | 80/251 [07:39<16:43,  5.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  32%|███▏      | 81/251 [07:44<16:01,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  33%|███▎      | 82/251 [07:50<15:41,  5.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  33%|███▎      | 83/251 [07:56<15:50,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  33%|███▎      | 84/251 [08:01<15:24,  5.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  34%|███▍      | 85/251 [08:08<16:57,  6.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  34%|███▍      | 86/251 [08:15<16:58,  6.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  35%|███▍      | 87/251 [08:20<16:08,  5.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  35%|███▌      | 88/251 [08:26<16:23,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  35%|███▌      | 89/251 [08:31<15:34,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  36%|███▌      | 90/251 [08:36<14:48,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  36%|███▋      | 91/251 [08:42<14:33,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  37%|███▋      | 92/251 [08:48<14:56,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  37%|███▋      | 93/251 [08:54<15:02,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  37%|███▋      | 94/251 [09:00<15:29,  5.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  38%|███▊      | 95/251 [09:05<14:59,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  38%|███▊      | 96/251 [09:11<14:50,  5.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  39%|███▊      | 97/251 [09:17<14:31,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  39%|███▉      | 98/251 [09:23<14:43,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  39%|███▉      | 99/251 [09:27<13:43,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  40%|███▉      | 100/251 [09:33<13:41,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  40%|████      | 101/251 [09:39<14:07,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  41%|████      | 102/251 [09:44<13:54,  5.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  41%|████      | 103/251 [09:50<13:50,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  41%|████▏     | 104/251 [09:57<14:33,  5.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  42%|████▏     | 105/251 [10:03<14:54,  6.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  42%|████▏     | 106/251 [10:10<15:04,  6.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  43%|████▎     | 107/251 [10:15<14:15,  5.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  43%|████▎     | 108/251 [10:21<14:14,  5.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  43%|████▎     | 109/251 [10:27<13:58,  5.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  44%|████▍     | 110/251 [10:33<14:22,  6.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  44%|████▍     | 111/251 [10:39<13:34,  5.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  45%|████▍     | 112/251 [10:44<13:31,  5.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  45%|████▌     | 113/251 [10:50<12:58,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  45%|████▌     | 114/251 [10:54<12:09,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  46%|████▌     | 115/251 [11:01<12:47,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  46%|████▌     | 116/251 [11:06<12:36,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  47%|████▋     | 117/251 [11:11<12:10,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  47%|████▋     | 118/251 [11:16<11:54,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  47%|████▋     | 119/251 [11:23<12:49,  5.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  48%|████▊     | 120/251 [11:29<12:53,  5.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  48%|████▊     | 121/251 [11:36<13:13,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  49%|████▊     | 122/251 [11:41<12:35,  5.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  49%|████▉     | 123/251 [11:47<12:14,  5.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  49%|████▉     | 124/251 [11:52<11:49,  5.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  50%|████▉     | 125/251 [11:58<12:08,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  50%|█████     | 126/251 [12:05<12:34,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  51%|█████     | 127/251 [12:11<12:17,  5.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  51%|█████     | 128/251 [12:18<13:07,  6.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  51%|█████▏    | 129/251 [12:24<12:58,  6.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  52%|█████▏    | 130/251 [12:30<12:23,  6.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  52%|█████▏    | 131/251 [12:35<11:41,  5.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  53%|█████▎    | 132/251 [12:40<10:59,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  53%|█████▎    | 133/251 [12:45<10:20,  5.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  53%|█████▎    | 134/251 [12:50<10:16,  5.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  54%|█████▍    | 135/251 [12:56<10:29,  5.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  54%|█████▍    | 136/251 [13:01<10:29,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  55%|█████▍    | 137/251 [13:07<10:28,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  55%|█████▍    | 138/251 [13:12<10:03,  5.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  55%|█████▌    | 139/251 [13:17<09:45,  5.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  56%|█████▌    | 140/251 [13:22<09:54,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  56%|█████▌    | 141/251 [13:28<09:46,  5.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  57%|█████▋    | 142/251 [13:34<10:11,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  57%|█████▋    | 143/251 [13:40<10:17,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  57%|█████▋    | 144/251 [13:45<09:57,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  58%|█████▊    | 145/251 [13:50<09:23,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  58%|█████▊    | 146/251 [13:55<09:24,  5.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  59%|█████▊    | 147/251 [14:03<10:21,  5.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  59%|█████▉    | 148/251 [14:08<09:51,  5.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  59%|█████▉    | 149/251 [14:14<09:49,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  60%|█████▉    | 150/251 [14:19<09:26,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  60%|██████    | 151/251 [14:26<09:55,  5.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  61%|██████    | 152/251 [14:32<09:47,  5.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  61%|██████    | 153/251 [14:37<09:20,  5.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  61%|██████▏   | 154/251 [14:42<08:59,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  62%|██████▏   | 155/251 [14:49<09:19,  5.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  62%|██████▏   | 156/251 [14:54<09:08,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  63%|██████▎   | 157/251 [15:00<08:51,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  63%|██████▎   | 158/251 [15:05<08:28,  5.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  63%|██████▎   | 159/251 [15:11<08:50,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  64%|██████▎   | 160/251 [15:17<08:46,  5.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  64%|██████▍   | 161/251 [15:23<08:38,  5.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  65%|██████▍   | 162/251 [15:34<11:10,  7.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  65%|██████▍   | 163/251 [15:39<10:02,  6.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  65%|██████▌   | 164/251 [15:45<09:27,  6.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  66%|██████▌   | 165/251 [15:50<08:38,  6.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  66%|██████▌   | 166/251 [15:55<08:09,  5.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  67%|██████▋   | 167/251 [16:01<08:02,  5.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  67%|██████▋   | 168/251 [16:06<07:41,  5.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  67%|██████▋   | 169/251 [16:12<07:32,  5.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  68%|██████▊   | 170/251 [16:17<07:21,  5.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  68%|██████▊   | 171/251 [16:23<07:32,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  69%|██████▊   | 172/251 [16:28<07:11,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  69%|██████▉   | 173/251 [16:35<07:35,  5.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  69%|██████▉   | 174/251 [16:42<07:54,  6.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  70%|██████▉   | 175/251 [16:48<07:54,  6.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  70%|███████   | 176/251 [16:54<07:35,  6.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  71%|███████   | 177/251 [16:59<07:16,  5.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  71%|███████   | 178/251 [17:04<06:43,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  71%|███████▏  | 179/251 [17:11<07:04,  5.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  72%|███████▏  | 180/251 [17:16<06:39,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  72%|███████▏  | 181/251 [17:22<06:40,  5.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  73%|███████▎  | 182/251 [17:27<06:37,  5.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  73%|███████▎  | 183/251 [17:33<06:32,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  73%|███████▎  | 184/251 [17:39<06:19,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  74%|███████▎  | 185/251 [17:45<06:28,  5.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  74%|███████▍  | 186/251 [17:51<06:19,  5.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  75%|███████▍  | 187/251 [17:56<06:08,  5.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  75%|███████▍  | 188/251 [18:02<05:55,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  75%|███████▌  | 189/251 [18:06<05:29,  5.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  76%|███████▌  | 190/251 [18:11<05:21,  5.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  76%|███████▌  | 191/251 [18:16<05:07,  5.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  76%|███████▋  | 192/251 [18:22<05:06,  5.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  77%|███████▋  | 193/251 [18:28<05:20,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  77%|███████▋  | 194/251 [18:34<05:23,  5.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  78%|███████▊  | 195/251 [18:40<05:29,  5.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  78%|███████▊  | 196/251 [18:45<05:13,  5.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  78%|███████▊  | 197/251 [18:58<07:05,  7.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  79%|███████▉  | 198/251 [19:05<06:37,  7.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  79%|███████▉  | 199/251 [19:11<05:59,  6.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  80%|███████▉  | 200/251 [19:17<05:43,  6.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  80%|████████  | 201/251 [19:22<05:18,  6.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  80%|████████  | 202/251 [19:28<04:55,  6.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  81%|████████  | 203/251 [19:33<04:40,  5.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  81%|████████▏ | 204/251 [19:39<04:33,  5.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  82%|████████▏ | 205/251 [19:45<04:34,  5.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  82%|████████▏ | 206/251 [19:51<04:27,  5.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  82%|████████▏ | 207/251 [19:57<04:18,  5.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  83%|████████▎ | 208/251 [20:02<04:03,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  83%|████████▎ | 209/251 [20:07<03:54,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  84%|████████▎ | 210/251 [20:13<03:47,  5.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  84%|████████▍ | 211/251 [20:22<04:26,  6.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  84%|████████▍ | 212/251 [20:28<04:16,  6.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  85%|████████▍ | 213/251 [20:33<03:51,  6.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  85%|████████▌ | 214/251 [20:39<03:37,  5.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  86%|████████▌ | 215/251 [20:44<03:23,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  86%|████████▌ | 216/251 [20:50<03:22,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  86%|████████▋ | 217/251 [20:56<03:21,  5.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  87%|████████▋ | 218/251 [21:02<03:17,  5.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  87%|████████▋ | 219/251 [21:10<03:26,  6.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  88%|████████▊ | 220/251 [21:15<03:08,  6.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  88%|████████▊ | 221/251 [21:20<02:49,  5.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  88%|████████▊ | 222/251 [21:26<02:46,  5.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  89%|████████▉ | 223/251 [21:30<02:31,  5.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  89%|████████▉ | 224/251 [21:39<02:49,  6.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  90%|████████▉ | 225/251 [21:44<02:37,  6.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  90%|█████████ | 226/251 [21:52<02:41,  6.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  90%|█████████ | 227/251 [21:57<02:26,  6.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  91%|█████████ | 228/251 [22:05<02:32,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  91%|█████████ | 229/251 [22:11<02:25,  6.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  92%|█████████▏| 230/251 [22:18<02:16,  6.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  92%|█████████▏| 231/251 [22:23<02:00,  6.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  92%|█████████▏| 232/251 [22:28<01:50,  5.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  93%|█████████▎| 233/251 [22:33<01:40,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  93%|█████████▎| 234/251 [22:39<01:38,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  94%|█████████▎| 235/251 [22:44<01:29,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  94%|█████████▍| 236/251 [22:50<01:24,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  94%|█████████▍| 237/251 [22:56<01:19,  5.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  95%|█████████▍| 238/251 [23:02<01:15,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  95%|█████████▌| 239/251 [23:07<01:07,  5.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  96%|█████████▌| 240/251 [23:13<01:03,  5.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  96%|█████████▌| 241/251 [23:20<01:02,  6.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  96%|█████████▋| 242/251 [23:27<00:56,  6.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  97%|█████████▋| 243/251 [23:32<00:47,  6.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  97%|█████████▋| 244/251 [23:37<00:39,  5.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  98%|█████████▊| 245/251 [23:43<00:34,  5.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  98%|█████████▊| 246/251 [23:49<00:29,  5.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  98%|█████████▊| 247/251 [23:55<00:23,  5.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  99%|█████████▉| 248/251 [24:03<00:19,  6.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples:  99%|█████████▉| 249/251 [24:09<00:12,  6.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Processing samples: 100%|█████████▉| 250/251 [24:14<00:06,  6.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing samples: 100%|██████████| 251/251 [24:17<00:00,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 预测结果已保存到 model_predictions/lora_predictions_mistral.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ 解析预测结果中的“翻译结果”和“错误类型”\n",
    "def extract_translation_and_error_type(pred_text):\n",
    "    trans_match = re.search(r\"翻译结果：\\s*(.*?)\\n\", pred_text, re.DOTALL)\n",
    "    translation = trans_match.group(1).strip() if trans_match else \"\"\n",
    "\n",
    "    error_match = re.search(r\"错误类型：\\s*(.+)\", pred_text)\n",
    "    if error_match:\n",
    "        error_str = error_match.group(1).strip()\n",
    "        # 只提取1-4的数字，并使用集合去重\n",
    "        error_type = list({int(x) for x in re.findall(r\"\\d+\", error_str) if 1 <= int(x) <= 4})\n",
    "    else:\n",
    "        error_type = []\n",
    "\n",
    "    return translation, error_type\n",
    "\n",
    "tokenizer.padding_side = 'left'\n",
    "test_samples =list(test_ds)\n",
    "\n",
    "batch_size = 8\n",
    "all_results = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_samples), batch_size), desc=\"Processing samples\"):\n",
    "    batch = test_samples[i:i+batch_size]\n",
    "\n",
    "    # ✅ 构造输入\n",
    "    prompts = [\n",
    "        f\"\"\"<s>[INST]\n",
    "            你是一位老年服务机构的文书编辑，擅长将老人的口头叙述准确、清晰地转化为日常书面风格的中文文本，并判断语句中存在的错误类型。\n",
    "            句子中可能存在的错误类型：1. 句子成分缺失。2. 句子结构混乱。3. 句子成分错误。4. 句子成分冗余。\n",
    "            原文：{example['spoken_text']}\n",
    "            上下文(仅协助理解，不翻译): {example['context']}\n",
    "            仅输出原文那一句话的中文翻译结果和错误类型序号，不要输出思考过程，不要输出解释。请在你预测的翻译结果前写“翻译结果：”，错误类型前写“错误类型：”。\n",
    "            严格按照输出格式输出：\n",
    "            翻译结果：\n",
    "            错误类型：\n",
    "            [/INST]</s>\"\"\" for example in batch\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "    ).to(model.device)\n",
    "\n",
    "    def safe_decode(sequences, tokenizer):\n",
    "        vocab_size = tokenizer.vocab_size  # ChatGLMTokenizer 使用这个属性获取词表大小\n",
    "        cleaned = []\n",
    "        for seq in sequences:\n",
    "            if isinstance(seq, torch.Tensor):\n",
    "                seq = seq.tolist()\n",
    "            # 过滤掉不在词表范围内的 token\n",
    "            seq = [token for token in seq if 0 <= token < vocab_size]\n",
    "            cleaned.append(seq)\n",
    "        return tokenizer.batch_decode(cleaned, skip_special_tokens=True)\n",
    "\n",
    "    # ✅ 推理\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            num_beams=1,\n",
    "            do_sample=False,\n",
    "            temperature=0.2,\n",
    "            top_p=0.95,\n",
    "        )\n",
    "\n",
    "    outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "    #preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    preds = safe_decode(outputs, tokenizer)\n",
    "\n",
    "    # ✅ 处理每条预测结果\n",
    "    for pred_text, example in zip(preds, batch):\n",
    "        translation, predicted_error_type = extract_translation_and_error_type(pred_text)\n",
    "\n",
    "        # 转换原始标签为数组\n",
    "        true_error = example.get(\"error_type\", [])\n",
    "        if isinstance(true_error, int):\n",
    "            true_error = [true_error]\n",
    "        elif isinstance(true_error, str):\n",
    "            true_error = [int(x) for x in re.findall(r\"\\d+\", true_error)]\n",
    "\n",
    "        result = {\n",
    "            \"spoken_text\": example[\"spoken_text\"],\n",
    "            \"context\": example[\"context\"],\n",
    "            \"reference\": example[\"written_text\"],\n",
    "            \"ref_error_type\": true_error,\n",
    "            \"prediction\": translation,\n",
    "            \"pred_error_type\": predicted_error_type\n",
    "        }\n",
    "        all_results.append(result)\n",
    "\n",
    "# ✅ 保存结果到 JSON 文件\n",
    "output_file = \"./result/lora/lora_predictions_mistral.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ 预测结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2001 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.392 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "  1%|          | 13/2001 [00:00<01:02, 31.70it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (137 > 128). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 2001/2001 [00:16<00:00, 122.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各项指标的平均值：\n",
      "BLEU-1: 0.7572\n",
      "BLEU-2: 0.5709\n",
      "BLEU-3: 0.4541\n",
      "BLEU-4: 0.3759\n",
      "ROUGE-1: 0.6977\n",
      "ROUGE-2: 0.4605\n",
      "ROUGE-L: 0.6481\n",
      "BLEURT: 0.4604\n",
      "Joint Accuracy: 0.4997\n",
      "Acc-1: 0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 加载模型和 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./bleurt-base-128\", local_files_only=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./bleurt-base-128\", local_files_only=True)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 加载数据\n",
    "with open(\"./result/lora/lora_predictions_mistral.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "import importlib\n",
    "import evaluate\n",
    "importlib.reload(evaluate)  # 强制重新加载  \n",
    "from evaluate import calculate_all_metrics\n",
    "\n",
    "# 存储所有指标\n",
    "all_scores = []\n",
    "\n",
    "for item in tqdm(data):\n",
    "    reference = item[\"reference\"]\n",
    "    generated = item[\"prediction\"]\n",
    "    if not reference or not generated:\n",
    "        continue  # 跳过空文本样本\n",
    "    ref_error_types = item.get(\"ref_error_type\", [])\n",
    "    pred_error_types = item.get(\"pred_error_type\", [])\n",
    "\n",
    "    metrics = calculate_all_metrics(reference, generated, tokenizer, model, ref_error_types, pred_error_types, device)\n",
    "    all_scores.append(metrics)\n",
    "\n",
    "# 计算每个指标的平均值\n",
    "average_scores = {}\n",
    "for key in all_scores[0].keys():\n",
    "    average_scores[key] = np.mean([score[key] for score in all_scores])\n",
    "\n",
    "# 打印平均结果\n",
    "print(\"各项指标的平均值：\")\n",
    "for key, value in average_scores.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
